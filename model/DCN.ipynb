{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import  *\n",
    "from keras.models import  *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train  = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list = list(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list.remove('is_trade')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train[embedding_list]\n",
    "test_x = test[embedding_list]\n",
    "\n",
    "train_y = train['is_trade']\n",
    "test_y = test['is_trade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossLayer(layers.Layer):\n",
    "    \"\"\"DCN's Cross Layer\n",
    "    # Arguments\n",
    "        num_layers: Positive integer, layer depth of CrossLayer.\n",
    "        use_bias: Boolean, whether the layer uses a bias vector.\n",
    "        kernel_initializer: Initializer for the `kernel` weights matrix\n",
    "            (see [initializers](../initializers.md)).\n",
    "        bias_initializer: Initializer for the bias vector\n",
    "            (see [initializers](../initializers.md)).\n",
    "\n",
    "    # Input shape\n",
    "        a 3D input with shape `(batch_size, 1, input_dim)`.\n",
    "\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(batch_size, input_dim)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_layers,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 **kwargs):\n",
    "        super(CrossLayer, self).__init__(**kwargs)\n",
    "        self.num_layer = num_layers\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "        \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.input_dim = input_shape[-1]\n",
    "        self.W = []\n",
    "        self.bias = []\n",
    "        for i in range(self.num_layer):\n",
    "            self.W.append(self.add_weight(shape = (1, self.input_dim), \n",
    "                                          initializer = self.kernel_initializer, \n",
    "                                          name = 'kernel_' + str(i), \n",
    "                                          trainable = True))\n",
    "            \n",
    "            self.bias.append(self.add_weight(shape = (1, self.input_dim), \n",
    "                                                 initializer = self.bias_initializer, \n",
    "                                                 name = 'bias_' + str(i), \n",
    "                                                 trainable = True))\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, input):\n",
    "        for i in range(self.num_layer):\n",
    "            if i == 0:\n",
    "                cross = Lambda(lambda x: Add()([K.sum(self.W[i] * \n",
    "                                                       K.batch_dot(K.reshape(x, (-1, self.input_dim, 1)), x), \n",
    "                                                        1, keepdims = True), \n",
    "                                              self.bias[i], \n",
    "                                              x]))(input)\n",
    "            else:\n",
    "                if self.use_bias:\n",
    "                    cross = Lambda(lambda x: Add()([K.sum(self.W[i] * \n",
    "                                                           K.batch_dot(K.reshape(x, (-1, self.input_dim, 1)), input), \n",
    "                                                            1, keepdims = True), \n",
    "                                                  self.bias[i], \n",
    "                                                  x]))(cross)\n",
    "                else:\n",
    "                    cross = Lambda(lambda x: Add()([K.sum(self.W[i] * \n",
    "                                                       K.batch_dot(K.reshape(x, (-1, self.input_dim, 1)), input), \n",
    "                                                        1, keepdims = True),\n",
    "                                                   x]))(cross)\n",
    "                \n",
    "        return Flatten()(cross)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 3\n",
    "        assert input_shape[-1]\n",
    "        output_shape = [input_shape[0], input_shape[2]]\n",
    "        return tuple(output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCN():\n",
    "    def __init__(self,embedding_list,emb_size,train_x,train_y,test_x,test_y):\n",
    "        self.embedding_list = embedding_list\n",
    "        self.emb_size = emb_size\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        self.test_x  = test_x\n",
    "        self.test_y = test_y\n",
    "        self.mxlen_set = self.get_mxlen_set()\n",
    "        \n",
    "    def builtModel(self):\n",
    "        \n",
    "        emb_list =[]\n",
    "        inp_list = []\n",
    "        fm_list =[]\n",
    "        product_list = []\n",
    "                \n",
    "        \n",
    "        ### embedding part and fm part\n",
    "        for feat in self.embedding_list:\n",
    "            inp_temp = Input(shape=[1],name=feat)\n",
    "            emb_temp = Flatten()(Embedding(self.mxlen_set[feat],self.emb_size)(inp_temp))\n",
    "            fm_temp = Flatten()(Embedding(self.mxlen_set[feat],1)(inp_temp))\n",
    "            inp_list.append(inp_temp)\n",
    "            emb_list.append(emb_temp)\n",
    "            fm_list.append(fm_temp)\n",
    "        \n",
    "         \n",
    "        \n",
    "        ## fm product part\n",
    "            \n",
    "        for i in range(0,len(emb_list)):\n",
    "            for j in range(i+1,len(emb_list)):\n",
    "                temp = dot([emb_list[i],emb_list[j]],axes=1)\n",
    "                product_list.append(temp)\n",
    "                        \n",
    "        ## dnn part\n",
    "        \n",
    "        dnn_part = Dense(512,activation='relu')(concatenate(emb_list))\n",
    "        \n",
    "        ## fm_part\n",
    "        fm_part = Dense(512,activation='relu')(concatenate(product_list+fm_list))\n",
    "        \n",
    "        inp = Dense(64,activation='relu')(concatenate([dnn_part,fm_part],axis=1))\n",
    "        \n",
    "        outp = Dense(1,activation='sigmoid')(inp)\n",
    "        \n",
    "        model = Model(inputs=inp_list,outputs=outp)\n",
    "        \n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "        \n",
    "                    \n",
    "    def get_mxlen_set(self):\n",
    "        X = {}\n",
    "        for ebd in self.embedding_list:\n",
    "            X[ebd] = np.max([self.train_x[ebd].max(),self.test_x[ebd].max()])+1\n",
    "        return X\n",
    "            \n",
    "    def get_kears_data(self,data):\n",
    "        X = {}\n",
    "        for ebd in self.embedding_list:\n",
    "            X[ebd] = np.array(data[ebd])\n",
    "        return X\n",
    "    \n",
    "    def train(self,batch_size,epochs):\n",
    "        self.model = self.builtModel()\n",
    "        X_train = self.get_kears_data(self.train_x)\n",
    "        self.model.fit(X_train,self.train_y,batch_size=batch_size,epochs=epochs,verbose=10)\n",
    "            \n",
    "    def predict(self,batch_size):\n",
    "        X_val = self.get_kears_data(self.test_x)\n",
    "        pred = self.model.predict(X_val,batch_size=batch_size)[:,0]\n",
    "        return pred\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
